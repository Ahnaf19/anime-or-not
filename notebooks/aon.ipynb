{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Anime-Or-Not"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## library import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import kagglehub\n",
    "import os\n",
    "from pathlib import Path\n",
    "from typing import List, Tuple, Optional\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.auto import tqdm\n",
    "from timeit import default_timer as timer \n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torchvision import datasets, transforms, models\n",
    "from  torch.utils.data import DataLoader, random_split, Dataset\n",
    "from  torchinfo import summary\n",
    "import wandb\n",
    "\n",
    "import random\n",
    "from PIL import Image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup device-agnostic code\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## download images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download latest version data\n",
    "\n",
    "path = kagglehub.dataset_download(\"kanakmittal/anime-and-cartoon-image-classification\")\n",
    "print(\"Path to dataset files:\", path)\n",
    "\n",
    "# then copy the files to the desired location --> ../data/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "now copy the downloaded `Training Data/` to `../data/`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = Path(\"../data/\")\n",
    "image_path = data_path / \"Training Data\"\n",
    "\n",
    " # check if the image folder exists\n",
    "if image_path.is_dir():\n",
    "    print(f\"'{image_path}' directory exists. Good to go.\")\n",
    "else:\n",
    "    print(f\"Did not find '{image_path}' directory, please download the dataset and extract it to the correct location: '{data_path}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(data_path), type(image_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def walk_through_dir(dir_path):\n",
    "  \"\"\"\n",
    "  Walks through dir_path returning its contents.\n",
    "  Args:\n",
    "    dir_path (str or pathlib.Path): target directory\n",
    "  \n",
    "  Returns:\n",
    "    A print out of:\n",
    "      number of subdiretories in dir_path\n",
    "      number of images (files) in each subdirectory\n",
    "      name of each subdirectory\n",
    "  \"\"\"\n",
    "  for dirpath, dirnames, filenames in os.walk(dir_path):\n",
    "    print(f\"There are {len(dirnames)} directories and {len(filenames)} images in '{dirpath}'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "walk_through_dir(image_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize an image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(150)\n",
    "\n",
    "image_path_list = list(image_path.glob(\"**/*.jpg\"))\n",
    "random_image_path = random.choice(image_path_list)\n",
    "image_class = random_image_path.parent.parent.name\n",
    "\n",
    "img = Image.open(random_image_path)\n",
    "\n",
    "# Turn the image into an array\n",
    "img_as_array = np.asarray(img)\n",
    "\n",
    "# Plot the image with matplotlib\n",
    "plt.figure(figsize=(10, 7))\n",
    "plt.imshow(img_as_array)\n",
    "plt.title(f\"Image class: {image_class} | Image shape: {img_as_array.shape} -> [H, W, C]\")\n",
    "plt.axis(False);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load images into pytorch\n",
    "\n",
    "before we can use our image data with pytorch we need to:\n",
    "\n",
    "- turn it into `tensors` (numerical representations of our images)\n",
    "- turn it into a `torch.utils.data.Dataset` and subsequently a `torch.util.data.DataLoader`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define transformations (resize, normalize, convert to tensor)\n",
    "\n",
    "img_resize = (224, 224) # Resize images to 224x224 for ResNet\n",
    "\n",
    "train_data_transform = transforms.Compose([\n",
    "    transforms.Resize(img_resize),\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.RandomApply([transforms.RandomRotation(degrees=(-30, 30))], p=0.5),\n",
    "    transforms.ToTensor(),  # Convert to tensor\n",
    "    # transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]), # TODO: how to set these values?\n",
    "]) # TODO: try with different transformations\n",
    "\n",
    "test_data_transform = transforms.Compose([\n",
    "    transforms.Resize(img_resize),\n",
    "    transforms.ToTensor(),  # Convert to tensor\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a wrapper to apply different transforms, use separate transforms for training and testing\n",
    "class TransformedDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, subset, transform):\n",
    "        self.dataset = subset.dataset\n",
    "        self.indices = subset.indices\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.indices)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img, label = self.dataset[self.indices[idx]]  # Get image & label\n",
    "        img = self.transform(img)  # Apply transform\n",
    "        return img, label\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "with this composition of transforms, let's try them out on various images:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_transformed_images(image_paths, transform, n=3, seed=150):\n",
    "    \"\"\"Plots a series of random images from image_paths.\n",
    "\n",
    "    Will open n image paths from image_paths, transform them\n",
    "    with transform and plot them side by side.\n",
    "\n",
    "    Args:\n",
    "        image_paths (list): List of target image paths. \n",
    "        transform (PyTorch Transforms): Transforms to apply to images.\n",
    "        n (int, optional): Number of images to plot. Defaults to 3.\n",
    "        seed (int, optional): Random seed for the random generator. Defaults to 150.\n",
    "    \"\"\"\n",
    "    random.seed(seed)\n",
    "    random_image_paths = random.sample(image_paths, k=n)\n",
    "    for image_path in random_image_paths:\n",
    "        with Image.open(image_path) as f:\n",
    "            fig, ax = plt.subplots(1, 2)\n",
    "            ax[0].imshow(f) \n",
    "            ax[0].set_title(f\"Original \\nSize: {f.size}\")\n",
    "            ax[0].axis(\"off\")\n",
    "\n",
    "            # Transform and plot image\n",
    "            # Note: permute() will change shape of image to suit matplotlib \n",
    "            # (PyTorch default is [C, H, W] but Matplotlib is [H, W, C])\n",
    "            transformed_image = transform(f).permute(1, 2, 0) \n",
    "            ax[1].imshow(transformed_image) \n",
    "            ax[1].set_title(f\"Transformed \\nSize: {transformed_image.shape}\")\n",
    "            ax[1].axis(\"off\")\n",
    "\n",
    "            fig.suptitle(f\"Class: {image_path.parent.parent.stem}\", fontsize=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path_list = list(image_path.glob(\"**/*.jpg\"))\n",
    "plot_transformed_images(image_path_list, transform=train_data_transform, n=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "# dataset = datasets.ImageFolder(root=image_path, transform=train_data_transform)\n",
    "dataset = datasets.ImageFolder(root=image_path) # no transform applied"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### train-test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into train & test\n",
    "train_size = int(0.8 * len(dataset))  # 80% train, 20% test\n",
    "test_size = len(dataset) - train_size\n",
    "train_data, test_data = random_split(dataset, [train_size, test_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply different transforms\n",
    "train_data = TransformedDataset(train_data, train_data_transform)\n",
    "test_data = TransformedDataset(test_data, test_data_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Train data:\\nDataset size: {len(train_data)}\\nTransform: {train_data.transform}\\n\")\n",
    "print(f\"Test data:\\nDataset size: {len(test_data)}\\nTransform: {test_data.transform}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = dataset.classes\n",
    "class_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_dict = dataset.class_to_idx\n",
    "class_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train_data), len(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "can index `train_data`, `test_data` to find samples and their target labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img, label = train_data[0][0], train_data[0][1]\n",
    "print(f\"Image tensor:\\n{img}\")\n",
    "print(f\"Image shape: {img.shape}\")\n",
    "print(f\"Image datatype: {img.dtype}\")\n",
    "print(f\"Image label: {label}\")\n",
    "print(f\"Label datatype: {type(label)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "now can plot image tensors as well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rearrange the order of dimensions\n",
    "img_permute = img.permute(1, 2, 0)\n",
    "\n",
    "# Print out different shapes (before and after permute)\n",
    "print(f\"Original shape: {img.shape} -> [C, H, W]\")\n",
    "print(f\"Image permute shape: {img.shape} -> [H, W, C]\")\n",
    "\n",
    "# Plot the image\n",
    "plt.figure(figsize=(10, 7))\n",
    "plt.imshow(img.permute(1, 2, 0))\n",
    "plt.axis(\"off\")\n",
    "plt.title(class_names[label], fontsize=14);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Take in a Dataset as well as a list of class names\n",
    "def display_random_images(dataset: Dataset,\n",
    "                          classes: list[str] | None = None,\n",
    "                          n: int = 10,\n",
    "                          display_shape: bool = True,\n",
    "                          seed: int | None = None):\n",
    "    \n",
    "    # 2. Adjust display if n too high\n",
    "    if n > 10:\n",
    "        n = 10\n",
    "        display_shape = False\n",
    "        print(f\"For display purposes, n shouldn't be larger than 10, setting to 10 and removing shape display.\")\n",
    "    \n",
    "    # 3. Set random seed\n",
    "    if seed:\n",
    "        random.seed(seed)\n",
    "\n",
    "    # 4. Get random sample indexes\n",
    "    random_samples_idx = random.sample(range(len(dataset)), k=n)\n",
    "\n",
    "    # 5. Setup plot\n",
    "    plt.figure(figsize=(16, 8))\n",
    "\n",
    "    # 6. Loop through samples and display random samples \n",
    "    for i, targ_sample in enumerate(random_samples_idx):\n",
    "        targ_image, targ_label = dataset[targ_sample][0], dataset[targ_sample][1]\n",
    "\n",
    "        # 7. Adjust image tensor shape for plotting: [color_channels, height, width] -> [color_channels, height, width]\n",
    "        targ_image_adjust = targ_image.permute(1, 2, 0)\n",
    "\n",
    "        # Plot adjusted samples\n",
    "        plt.subplot(1, n, i+1)\n",
    "        plt.imshow(targ_image_adjust)\n",
    "        plt.axis(\"off\")\n",
    "        if classes:\n",
    "            title = f\"class: {classes[targ_label]}\"\n",
    "            if display_shape:\n",
    "                title = title + f\"\\nshape: {targ_image_adjust.shape}\"\n",
    "        plt.title(title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display random images from ImageFolder created Dataset\n",
    "display_random_images(train_data, \n",
    "                      n=5, \n",
    "                      classes=class_names,\n",
    "                      seed=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### dataloaders\n",
    "\n",
    "Turning our `Dataset`'s into `DataLoader`'s makes them iterable so a model can go through and learn the relationships between samples and targets (features and labels)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.cpu_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try loading a single sample without DataLoader\n",
    "img, label = train_data[0]  # Fetch first sample manually\n",
    "print(f\"Single image type: {type(img)}\")  # Should be a torch.Tensor\n",
    "print(f\"Single image shape: {img.shape}\")  # Should be [C, H, W]\n",
    "print(f\"Label: {label}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_dataloader = DataLoader(\n",
    "#     dataset=train_data, \n",
    "#     batch_size=32,  # Start with a small batch\n",
    "#     num_workers=1,  # Avoid multiprocessing issues for now\n",
    "#     shuffle=True, \n",
    "#     pin_memory=True\n",
    "# )\n",
    "\n",
    "# img_batch, label_batch = next(iter(train_dataloader))  # Try fetching a batch\n",
    "# print(f\"Batch Image shape: {img_batch.shape}\")  # Should be [batch_size, C, H, W]\n",
    "# print(f\"Batch Label shape: {label_batch.shape}\")  # Should be [batch_size]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(dataset=train_data, \n",
    "                              batch_size=32, # how many samples per batch?\n",
    "                              num_workers=0, # number of processes to use, 0 as its showing issues\n",
    "                              shuffle=True, # shuffle the data?\n",
    "                              pin_memory=True # copy Tensors into CUDA pinned memory before returning them?\n",
    "                            )\n",
    "\n",
    "test_dataloader = DataLoader(dataset=test_data, \n",
    "                             batch_size=32, \n",
    "                             num_workers=0, \n",
    "                             shuffle=False, # don't usually need to shuffle testing data) \n",
    "                             pin_memory=True\n",
    "                            )\n",
    "train_dataloader, test_dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_batch, label_batch = next(iter(train_dataloader))  # Try fetching a batch\n",
    "print(f\"Batch Image shape: {img_batch.shape}\")  # Should be [batch_size, C, H, W]\n",
    "print(f\"Batch Label shape: {label_batch.shape}\")  # Should be [batch_size]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### download & load the pretrained model: ResNet50\n",
    "\n",
    "- load model's DEFAULT weights (best available weights)\n",
    "- initiate the model with pre trained weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NEW: Setup the model with pretrained weights and send it to the target device (torchvision v0.13+)\n",
    "weights = models.ResNet50_Weights.DEFAULT # .DEFAULT = best available weights \n",
    "model = models.resnet50(weights=weights).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### freeze classifier layer: fc layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "model summary: before freezing fc layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print model summary\n",
    "summary(model=model, \n",
    "        input_size=(32, 3, 224, 224), # make sure this is \"input_size\", not \"input_shape\"\n",
    "        col_names=[\"input_size\", \"output_size\", \"num_params\", \"trainable\"],\n",
    "        col_width=20,\n",
    "        row_settings=[\"var_names\"]\n",
    ") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "model.fc.requires_grad_(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "model summary: after freezing fc layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print model summary\n",
    "summary(model=model, \n",
    "        input_size=(32, 3, 224, 224), # make sure this is \"input_size\", not \"input_shape\"\n",
    "        col_names=[\"input_size\", \"output_size\", \"num_params\", \"trainable\"],\n",
    "        col_width=20,\n",
    "        row_settings=[\"var_names\"]\n",
    ") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### updating fc layer as per classification need"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "torch.cuda.manual_seed(42)\n",
    "\n",
    "output_shape= len(class_names)\n",
    "\n",
    "model.fc = torch.nn.Linear(\n",
    "    in_features=model.fc.in_features,\n",
    "    out_features=len(class_names),\n",
    "    bias=True\n",
    "    ).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do a summary *after* freezing the features and changing the output classifier layer\n",
    "summary(model, \n",
    "        input_size=(32, 3, 224, 224),\n",
    "        verbose=0,\n",
    "        col_names=[\"input_size\", \"output_size\", \"num_params\", \"trainable\"],\n",
    "        col_width=20,\n",
    "        row_settings=[\"var_names\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### single batch input output test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "try to pass single image and get prediction before training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Get a batch of images and labels from the DataLoader\n",
    "img_batch, label_batch = next(iter(train_dataloader))\n",
    "\n",
    "# 2. Get a single image from the batch and unsqueeze the image so its shape fits the model\n",
    "img_single, label_single = img_batch[0].unsqueeze(dim=0), label_batch[0]\n",
    "print(f\"Single image shape: {img_single.shape}\\n\")\n",
    "\n",
    "# 3. Perform a forward pass on a single image\n",
    "model.eval()\n",
    "with torch.inference_mode():\n",
    "    pred = model(img_single.to(device))\n",
    "    \n",
    "# 4. Print out what's happening and convert model logits -> pred probs -> pred label\n",
    "print(f\"Output logits:\\n{pred}\\n\")\n",
    "print(f\"Output prediction probabilities:\\n{torch.softmax(pred, dim=1)}\\n\")\n",
    "print(f\"Output prediction label:\\n{torch.argmax(torch.softmax(pred, dim=1), dim=1)}\\n\")\n",
    "print(f\"Actual label:\\n{label_single}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## train setup\n",
    "\n",
    "- train_step\n",
    "- test_step\n",
    "- train --> train_step + test_step\n",
    "- seed\n",
    "- loss function and optimizer\n",
    "- model\n",
    "\n",
    "then its ready to begin training!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### train_step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_step(model: torch.nn.Module, \n",
    "               dataloader: torch.utils.data.DataLoader, \n",
    "               loss_fn: torch.nn.Module, \n",
    "               optimizer: torch.optim.Optimizer):\n",
    "    # Put model in train mode\n",
    "    model.train()\n",
    "    \n",
    "    # Setup train loss and train accuracy values\n",
    "    train_loss, train_acc = 0, 0\n",
    "    \n",
    "    # Loop through data loader data batches\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        # Send data to target device\n",
    "        X, y = X.to(device), y.to(device)\n",
    "\n",
    "        # 1. Forward pass\n",
    "        y_pred = model(X)\n",
    "\n",
    "        # 2. Calculate  and accumulate loss\n",
    "        loss = loss_fn(y_pred, y)\n",
    "        train_loss += loss.item() \n",
    "\n",
    "        # 3. Optimizer zero grad\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # 4. Loss backward\n",
    "        loss.backward()\n",
    "\n",
    "        # 5. Optimizer step\n",
    "        optimizer.step()\n",
    "\n",
    "        # Calculate and accumulate accuracy metrics across all batches\n",
    "        y_pred_class = torch.argmax(torch.softmax(y_pred, dim=1), dim=1)\n",
    "        train_acc += (y_pred_class == y).sum().item()/len(y_pred)\n",
    "\n",
    "    # Adjust metrics to get average loss and accuracy per batch \n",
    "    train_loss = train_loss / len(dataloader)\n",
    "    train_acc = train_acc / len(dataloader)\n",
    "    return train_loss, train_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### test_step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_step(model: torch.nn.Module, \n",
    "              dataloader: torch.utils.data.DataLoader, \n",
    "              loss_fn: torch.nn.Module):\n",
    "    # Put model in eval mode\n",
    "    model.eval() \n",
    "    \n",
    "    # Setup test loss and test accuracy values\n",
    "    test_loss, test_acc = 0, 0\n",
    "    \n",
    "    # Turn on inference context manager\n",
    "    with torch.inference_mode():\n",
    "        # Loop through DataLoader batches\n",
    "        for batch, (X, y) in enumerate(dataloader):\n",
    "            # Send data to target device\n",
    "            X, y = X.to(device), y.to(device)\n",
    "    \n",
    "            # 1. Forward pass\n",
    "            test_pred_logits = model(X)\n",
    "\n",
    "            # 2. Calculate and accumulate loss\n",
    "            loss = loss_fn(test_pred_logits, y)\n",
    "            test_loss += loss.item()\n",
    "            \n",
    "            # Calculate and accumulate accuracy\n",
    "            test_pred_labels = test_pred_logits.argmax(dim=1)\n",
    "            test_acc += ((test_pred_labels == y).sum().item()/len(test_pred_labels))\n",
    "            \n",
    "    # Adjust metrics to get average loss and accuracy per batch \n",
    "    test_loss = test_loss / len(dataloader)\n",
    "    test_acc = test_acc / len(dataloader)\n",
    "    return test_loss, test_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Take in various parameters required for training and test steps\n",
    "def train(model: torch.nn.Module, \n",
    "          train_dataloader: torch.utils.data.DataLoader, \n",
    "          test_dataloader: torch.utils.data.DataLoader, \n",
    "          optimizer: torch.optim.Optimizer,\n",
    "          loss_fn: torch.nn.Module = nn.CrossEntropyLoss(),\n",
    "          epochs: int = 5):\n",
    "    \n",
    "    # 2. Create empty results dictionary\n",
    "    results = {\"train_loss\": [],\n",
    "        \"train_acc\": [],\n",
    "        \"test_loss\": [],\n",
    "        \"test_acc\": []\n",
    "    }\n",
    "    \n",
    "    # 3. Loop through training and testing steps for a number of epochs\n",
    "    for epoch in tqdm(range(epochs)):\n",
    "        train_loss, train_acc = train_step(model=model,\n",
    "                                           dataloader=train_dataloader,\n",
    "                                           loss_fn=loss_fn,\n",
    "                                           optimizer=optimizer)\n",
    "        test_loss, test_acc = test_step(model=model,\n",
    "            dataloader=test_dataloader,\n",
    "            loss_fn=loss_fn)\n",
    "        \n",
    "        # 4. Print out what's happening\n",
    "        print(\n",
    "            f\"Epoch: {epoch+1} | \"\n",
    "            f\"train_loss: {train_loss:.4f} | \"\n",
    "            f\"train_acc: {train_acc:.4f} | \"\n",
    "            f\"test_loss: {test_loss:.4f} | \"\n",
    "            f\"test_acc: {test_acc:.4f}\"\n",
    "        )\n",
    "\n",
    "        # 5. Update results dictionary\n",
    "        # Ensure all data is moved to CPU and converted to float for storage\n",
    "        results[\"train_loss\"].append(train_loss.item() if isinstance(train_loss, torch.Tensor) else train_loss)\n",
    "        results[\"train_acc\"].append(train_acc.item() if isinstance(train_acc, torch.Tensor) else train_acc)\n",
    "        results[\"test_loss\"].append(test_loss.item() if isinstance(test_loss, torch.Tensor) else test_loss)\n",
    "        results[\"test_acc\"].append(test_acc.item() if isinstance(test_acc, torch.Tensor) else test_acc)\n",
    "\n",
    "    # 6. Return the filled results at the end of the epochs\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set random seeds\n",
    "torch.manual_seed(42) \n",
    "torch.cuda.manual_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### loss function & optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define loss and optimizer\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set number of epochs\n",
    "NUM_EPOCHS = 2\n",
    "\n",
    "# Start the timer\n",
    "start_time = timer()\n",
    "\n",
    "# Train model \n",
    "model_results = train(model=model, \n",
    "                        train_dataloader=train_dataloader,\n",
    "                        test_dataloader=test_dataloader,\n",
    "                        optimizer=optimizer,\n",
    "                        loss_fn=loss_fn, \n",
    "                        epochs=NUM_EPOCHS)\n",
    "\n",
    "# End the timer and print out how long it took\n",
    "end_time = timer()\n",
    "print(f\"Total training time: {end_time-start_time:.3f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## loss curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the model_results keys\n",
    "model_results.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_loss_curves(results: dict[str, list[float]]):\n",
    "    \"\"\"Plots training curves of a results dictionary.\n",
    "\n",
    "    Args:\n",
    "        results (dict): dictionary containing list of values, e.g.\n",
    "            {\"train_loss\": [...],\n",
    "             \"train_acc\": [...],\n",
    "             \"test_loss\": [...],\n",
    "             \"test_acc\": [...]}\n",
    "    \"\"\"\n",
    "    \n",
    "    # Get the loss values of the results dictionary (training and test)\n",
    "    loss = results['train_loss']\n",
    "    test_loss = results['test_loss']\n",
    "\n",
    "    # Get the accuracy values of the results dictionary (training and test)\n",
    "    accuracy = results['train_acc']\n",
    "    test_accuracy = results['test_acc']\n",
    "\n",
    "    # Figure out how many epochs there were\n",
    "    epochs = range(len(results['train_loss']))\n",
    "\n",
    "    # Setup a plot \n",
    "    plt.figure(figsize=(15, 7))\n",
    "\n",
    "    # Plot loss\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(epochs, loss, label='train_loss')\n",
    "    plt.plot(epochs, test_loss, label='test_loss')\n",
    "    plt.title('Loss')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.legend()\n",
    "\n",
    "    # Plot accuracy\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(epochs, accuracy, label='train_accuracy')\n",
    "    plt.plot(epochs, test_accuracy, label='test_accuracy')\n",
    "    plt.title('Accuracy')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_loss_curves(model_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## export model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# uncomment to use\n",
    "# torch.save(model.state_dict(), \"../models/model.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## model tracking with wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Take in various parameters required for training and test steps\n",
    "def train(model: torch.nn.Module, \n",
    "          train_dataloader: torch.utils.data.DataLoader, \n",
    "          test_dataloader: torch.utils.data.DataLoader, \n",
    "          optimizer: torch.optim.Optimizer,\n",
    "          loss_fn: torch.nn.Module = nn.CrossEntropyLoss(),\n",
    "          epochs: int = 5,\n",
    "          wandb_log: bool = False):\n",
    "    \n",
    "    # 2. Create empty results dictionary\n",
    "    results = {\"train_loss\": [],\n",
    "        \"train_acc\": [],\n",
    "        \"test_loss\": [],\n",
    "        \"test_acc\": []\n",
    "    }\n",
    "    \n",
    "    # 3. Loop through training and testing steps for a number of epochs\n",
    "    for epoch in tqdm(range(epochs)):\n",
    "        train_loss, train_acc = train_step(model=model,\n",
    "                                           dataloader=train_dataloader,\n",
    "                                           loss_fn=loss_fn,\n",
    "                                           optimizer=optimizer)\n",
    "        test_loss, test_acc = test_step(model=model,\n",
    "            dataloader=test_dataloader,\n",
    "            loss_fn=loss_fn)\n",
    "        \n",
    "        # 4. Print out what's happening\n",
    "        print(\n",
    "            f\"Epoch: {epoch+1} | \"\n",
    "            f\"train_loss: {train_loss:.4f} | \"\n",
    "            f\"train_acc: {train_acc:.4f} | \"\n",
    "            f\"test_loss: {test_loss:.4f} | \"\n",
    "            f\"test_acc: {test_acc:.4f}\"\n",
    "        )\n",
    "\n",
    "        # 5. Update results dictionary\n",
    "        # Ensure all data is moved to CPU and converted to float for storage\n",
    "        results[\"train_loss\"].append(train_loss.item() if isinstance(train_loss, torch.Tensor) else train_loss)\n",
    "        results[\"train_acc\"].append(train_acc.item() if isinstance(train_acc, torch.Tensor) else train_acc)\n",
    "        results[\"test_loss\"].append(test_loss.item() if isinstance(test_loss, torch.Tensor) else test_loss)\n",
    "        results[\"test_acc\"].append(test_acc.item() if isinstance(test_acc, torch.Tensor) else test_acc)\n",
    "        \n",
    "        # Log results to wandb\n",
    "        if wandb_log:\n",
    "            wandb.log(\n",
    "                {\n",
    "                    \"epoch\": epoch,\n",
    "                    \"train_loss\": train_loss,\n",
    "                    \"train_acc\": train_acc,\n",
    "                    \"test_loss\": test_loss,\n",
    "                    \"test_acc\": test_acc\n",
    "                }\n",
    "            )\n",
    "            \n",
    "    if wandb_log:        \n",
    "        wandb.finish()\n",
    "    \n",
    "    # 6. Return the filled results at the end of the epochs\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_wandb(\n",
    "    model: torch.nn.Module,\n",
    "    train_dataloader: torch.utils.data.DataLoader,\n",
    "    test_dataloader: torch.utils.data.DataLoader,\n",
    "    optimizer: torch.optim.Optimizer,\n",
    "    wandb_run_name: str,\n",
    "    loss_fn: torch.nn.Module,\n",
    "    n_epochs: int = 5,\n",
    "    wandb_project_name: str = \"anime-or-not\",\n",
    "    wandb_log: bool = True,\n",
    "    config: dict = {\"config\":'empty'} # Pass in a dictionary of configuration for wandb\n",
    "):\n",
    "    # Initialize wandb\n",
    "    if wandb_log:\n",
    "        wandb.init(project=wandb_project_name, name=wandb_run_name)\n",
    "        wandb.watch(model, log=\"all\")\n",
    "        wandb.config = {**config}\n",
    "\n",
    "    # Start the timer\n",
    "    start_time = timer()\n",
    "\n",
    "    # Train model \n",
    "    model_results = train(model=model, \n",
    "                            train_dataloader=train_dataloader,\n",
    "                            test_dataloader=test_dataloader,\n",
    "                            optimizer=optimizer,\n",
    "                            loss_fn=loss_fn, \n",
    "                            epochs=n_epochs,\n",
    "                            wandb_log=wandb_log)\n",
    "\n",
    "    # End the timer and print out how long it took\n",
    "    end_time = timer()\n",
    "    print(f\"Total training time: {end_time-start_time:.3f} seconds\")\n",
    "    \n",
    "    return model_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### run1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(42) \n",
    "torch.cuda.manual_seed(42)\n",
    "\n",
    "lr= 0.001\n",
    "n_epochs = 20\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "config= {\n",
    "    \"model\": \"ResNet50-v0\",\n",
    "    \"pretrained\": \"imagenet\",\n",
    "    \"optimizer\": \"Adam\",\n",
    "    \"learning_rate\": lr,\n",
    "    \"epochs\": n_epochs\n",
    "}\n",
    "\n",
    "model_results = train_wandb(\n",
    "    model=model,\n",
    "    train_dataloader=train_dataloader,\n",
    "    test_dataloader=test_dataloader,\n",
    "    optimizer=optimizer,\n",
    "    wandb_run_name=\"ResNet50-v0-run1\",\n",
    "    loss_fn=loss_fn,\n",
    "    n_epochs=n_epochs,\n",
    "    wandb_project_name=\"anime-or-not\",\n",
    "    wandb_log=True,\n",
    "    config=config\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_loss_curves(model_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### run2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(42) \n",
    "torch.cuda.manual_seed(42)\n",
    "\n",
    "lr= 0.002\n",
    "n_epochs = 20\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "config= {\n",
    "    \"model\": \"ResNet50-v0\",\n",
    "    \"pretrained\": \"imagenet\",\n",
    "    \"optimizer\": \"Adam\",\n",
    "    \"learning_rate\": lr,\n",
    "    \"epochs\": n_epochs\n",
    "}\n",
    "\n",
    "model_results = train_wandb(\n",
    "    model=model,\n",
    "    train_dataloader=train_dataloader,\n",
    "    test_dataloader=test_dataloader,\n",
    "    optimizer=optimizer,\n",
    "    wandb_run_name=\"ResNet50-v0-run2\",\n",
    "    loss_fn=loss_fn,\n",
    "    n_epochs=n_epochs,\n",
    "    wandb_project_name=\"anime-or-not\",\n",
    "    wandb_log=True,\n",
    "    config=config\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_loss_curves(model_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### run3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(42) \n",
    "torch.cuda.manual_seed(42)\n",
    "\n",
    "lr= 0.0015\n",
    "n_epochs = 50\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "config= {\n",
    "    \"model\": \"ResNet50-v0\",\n",
    "    \"pretrained\": \"imagenet\",\n",
    "    \"optimizer\": \"Adam\",\n",
    "    \"learning_rate\": lr,\n",
    "    \"epochs\": n_epochs\n",
    "}\n",
    "\n",
    "model_results = train_wandb(\n",
    "    model=model,\n",
    "    train_dataloader=train_dataloader,\n",
    "    test_dataloader=test_dataloader,\n",
    "    optimizer=optimizer,\n",
    "    wandb_run_name=\"ResNet50-v0-run3\",\n",
    "    loss_fn=loss_fn,\n",
    "    n_epochs=n_epochs,\n",
    "    wandb_project_name=\"anime-or-not\",\n",
    "    wandb_log=True,\n",
    "    config=config\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_loss_curves(model_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### run4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "next(model.parameters()).device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(42) \n",
    "torch.cuda.manual_seed(42)\n",
    "\n",
    "lr= 0.00090\n",
    "n_epochs = 50\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "config= {\n",
    "    \"model\": \"ResNet50-v0\",\n",
    "    \"pretrained\": \"imagenet\",\n",
    "    \"optimizer\": \"Adam\",\n",
    "    \"learning_rate\": lr,\n",
    "    \"epochs\": n_epochs\n",
    "}\n",
    "\n",
    "model_results = train_wandb(\n",
    "    model=model,\n",
    "    train_dataloader=train_dataloader,\n",
    "    test_dataloader=test_dataloader,\n",
    "    optimizer=optimizer,\n",
    "    wandb_run_name=\"ResNet50-v0-run4\",\n",
    "    loss_fn=loss_fn,\n",
    "    n_epochs=n_epochs,\n",
    "    wandb_project_name=\"anime-or-not\",\n",
    "    wandb_log=True,\n",
    "    config=config\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_loss_curves(model_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# uncomment to use\n",
    "# torch.save(model.state_dict(), \"../models/model-run4.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### run5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "next(model.parameters()).device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(42) \n",
    "torch.cuda.manual_seed(42)\n",
    "\n",
    "lr= 0.0011\n",
    "n_epochs = 50\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "config= {\n",
    "    \"model\": \"ResNet50-v0\",\n",
    "    \"pretrained\": \"imagenet\",\n",
    "    \"optimizer\": \"Adam\",\n",
    "    \"learning_rate\": lr,\n",
    "    \"epochs\": n_epochs\n",
    "}\n",
    "\n",
    "model_results = train_wandb(\n",
    "    model=model,\n",
    "    train_dataloader=train_dataloader,\n",
    "    test_dataloader=test_dataloader,\n",
    "    optimizer=optimizer,\n",
    "    wandb_run_name=\"ResNet50-v0-run5\",\n",
    "    loss_fn=loss_fn,\n",
    "    n_epochs=n_epochs,\n",
    "    wandb_project_name=\"anime-or-not\",\n",
    "    wandb_log=True,\n",
    "    config=config\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_loss_curves(model_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## make prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Take in a trained model, class names, image path, image size, a transform and target device\n",
    "def pred_and_plot_image(model: torch.nn.Module,\n",
    "                        image_path: str, \n",
    "                        class_names: List[str],\n",
    "                        image_size: Tuple[int, int] = (224, 224),\n",
    "                        transform: Optional[transforms.Compose] = None,\n",
    "                        device = device):\n",
    "    \n",
    "    \n",
    "    # 2. Open image\n",
    "    img = Image.open(image_path)\n",
    "\n",
    "    # 3. Create transformation for image (if one doesn't exist)\n",
    "    if transform is not None:\n",
    "        image_transform = transform\n",
    "    else:\n",
    "        image_transform = transforms.Compose([\n",
    "            transforms.Resize(image_size),\n",
    "            transforms.ToTensor()\n",
    "        #     transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "        #                          std=[0.229, 0.224, 0.225]),\n",
    "        ])\n",
    "\n",
    "    ### Predict on image ### \n",
    "\n",
    "    # 4. Make sure the model is on the target device\n",
    "    model.to(device)\n",
    "\n",
    "    # 5. Turn on model evaluation mode and inference mode\n",
    "    model.eval()\n",
    "    with torch.inference_mode():\n",
    "      # 6. Transform and add an extra dimension to image (model requires samples in [batch_size, color_channels, height, width])\n",
    "      transformed_image = image_transform(img).unsqueeze(dim=0)\n",
    "\n",
    "      # 7. Make a prediction on image with an extra dimension and send it to the target device\n",
    "      target_image_pred = model(transformed_image.to(device))\n",
    "\n",
    "    # 8. Convert logits -> prediction probabilities (using torch.softmax() for multi-class classification)\n",
    "    target_image_pred_probs = torch.softmax(target_image_pred, dim=1)\n",
    "\n",
    "    # 9. Convert prediction probabilities -> prediction labels\n",
    "    target_image_pred_label = torch.argmax(target_image_pred_probs, dim=1)\n",
    "\n",
    "    # 10. Plot image with predicted label and probability \n",
    "    plt.figure()\n",
    "    plt.imshow(img)\n",
    "    plt.title(f\"Pred: {class_names[target_image_pred_label]} | Prob: {target_image_pred_probs.max():.3f}\")\n",
    "    plt.axis(False);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aon",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
